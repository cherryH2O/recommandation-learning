    用于找到文本的隐含语义。
    
#### 基础算法

- 核心思想是通过**隐含特征(latent factor)**联系用户兴趣和物品。
- 对于某个用户，首先得到他的**兴趣分类**，然后从分类中挑选他可能喜欢的物品。

- 基于兴趣分类的方法大概需要解决 3 个问题：
    - 如何给物品进行分类
    - 如何确定用户对哪些物品感兴趣，以及感兴趣的程度
    - 对于一个给定的类，选择哪些属于这个类的物品推荐给用户，以及如何确定这些物品在一个类中的权重。
    
- **隐含语义分析技术**因为采取基于用户行为统计的自动聚类
- 隐含语义分析技术从诞生到今天产生了很多著名的模型和方法，其中和该技术相关且耳熟能详的名词有pLSA 、 LDA 、隐含类别模型（ latent class model ）、隐含主题模型（latent topic model ）、 矩阵分解（ matrix factorization ）

#### 基于LFM的实际系统的例子

- 很难实现实时推荐
- 为了解决传统LFM不能实时化，而产品需要实时性的矛盾，雅虎的工作人员提出了一个解决方案。
  - 利用新闻链接的内容属性（关键词、类别等）得到链接i的内容特征向量
  - 实时收集用户对链接的行为，并且用这些数据得到链接i的隐特征向量
  - 然后预测用户是否会点击链接
  
#### LFM和基于邻域方法的比较
- LFM是一种基于机器学习的方法，具有比较好的理论基础。这个方法和基于邻域的方法（UserCF、ItemCF）相比，各有优缺点。

- 理论基础 
  - LFM具有**比较好的理论基础**，它是一种学习方法，通过优化一个设定的指标建立最优的模型。
  - 基于邻域方法更多是一种基于统计的方法，并没有学习过程。
- 离线计算的空间复杂度
  - 基于邻域的方法需要维护一张离线的相关表。数据大的话，会**更占用内存**。
- 离线计算的时间复杂度
  - 在一般情况下， LFM 的时间复杂度要稍微高于 UserCF 和 ItemCF，这主要是因为该算法需要多次迭代。
  - 但总体上，这两种算法在时间复杂度上没有质的差别。
- 在线实时推荐
  - 从 LFM 的预测公式可以看到， LFM
    在给用户生成推荐列表时，需要计算用户对所有物品的兴趣权重，然后排名，返回权重最大的 N 个物品。
  - LFM 在生成一个用户推荐列表时速度太慢，因此不能在线实
时计算，而需要离线将所有用户的推荐结果事先计算好存储在数据库中。因此， LFM 不
能进行在线实时推荐，也就是说，当用户有了新的行为后，他的推荐列表不会发生变化
- 推荐解释
  - ItemCF 算法支持很好的推荐解释，它可以利用用户的历史行为解释推荐结果。
  - LFM
    无法提供这样的解释，它计算出的隐类虽然在语义上确实代表了一类兴趣和物品，
    却很难用自然语言描述并生成解释展现给用户